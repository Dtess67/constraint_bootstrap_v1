import pytest
from constraint_bootstrap.bootstrap_agent_v1 import BootstrapAgentV1, Handle
from q_ternary.lane_v1 import Lane, Decision

def test_question_lane_semantics():
    """QUESTION lane never counted as correct/incorrect; only contributes via utility."""
    # We'll verify this via run_metrics_v1 computation logic
    from constraint_bootstrap.run_metrics_v1 import compute_metrics
    
    # 1 SPEAK correct, 1 SPEAK wrong, 1 QUESTION
    steps = [
        {"lane": "SPEAK", "pred_sig": "5", "act_sig": "5"},
        {"lane": "SPEAK", "pred_sig": "5", "act_sig": "7"},
        {"lane": "QUESTION", "pred_sig": "999", "act_sig": "5"}
    ]
    
    m = compute_metrics(steps, question_credit=0.5)
    
    # SPEAK accuracy = 1/2 = 0.5
    assert m["precision"] == 0.5
    # Question rate = 1/3
    assert m["question_rate"] == pytest.approx(1/3)
    # Utility = (speak_rate * precision) + (question_rate * credit)
    # Speak rate = 2/3. Utility = (2/3 * 0.5) + (1/3 * 0.5) = 1/3 + 1/6 = 0.5
    assert m["utility"] == pytest.approx(0.5)
    # Overall Accuracy (exact matches) = 1/3
    assert m["acc_exact"] == pytest.approx(1/3)

def test_question_lane_includes_template():
    """QUESTION lane always includes a non-empty question string when generated by agent."""
    agent = BootstrapAgentV1(seed=123, eligibility_min_to_consider=0.0)
    # Matching handle but below threshold
    agent._handles.append(Handle(hid="H001", sent_sig="4", resp_sig="5", strength=0.2))
    
    decision = agent.predict((4,))
    assert decision.lane == Lane.QUESTION
    assert decision.question is not None
    assert "is the correct act [5] or []?" in decision.question

def test_ambiguous_oracle_routing():
    """If oracle act is multi-label, trainer must not treat it as a wrong SPEAK."""
    from q_ternary.training.aggressive_trainer_v1 import AggressiveTrainerV1, TrainingSample
    
    agent = BootstrapAgentV1(seed=123)
    # Oracle gives [5,7] for some input
    # Mixed partner gives [5,7] for input with len=prime and sum=prime. e.g. (2,3)
    # len=2 (prime), sum=5 (prime)
    
    trainer = AggressiveTrainerV1(agent, partner_name="mixed", seed=123)
    sample = TrainingSample(sent=(2,3), sent_sig="2,3")
    
    res = trainer.run_inference(sample)
    assert res.oracle_ambiguous is True
    
    # Verify train_round behavior
    metrics = trainer.train_round(batch_size=1, drill_n=0, uncertainty_threshold=0.1, fixed_batch=[sample])
    
    # It should skip weight updates (corrected=False because should_learn=False for ambiguous oracle)
    assert metrics["corrections"] == 0
    assert not trainer.history[-1].corrected
